---
title: 2022暑期实习面试自我介绍
date: 2021-04-02 19:51:49
top: 1
tags: [面试]
categories: [面试]
---



面试自我介绍。

<!--more-->



面试官您好，我是来自xx大学NLP实验室的cm，目前研二在读。

在校期间主要做事件抽取，实体识别，关系抽取相关的工作。

目前有一篇论文录用和一篇论文在投。

第一篇论文是基于阅读理解框架的事件论元抽取。这篇论文我的主要创新在于**首次提出了适用于事件论元抽取的问答框架**，利用事件模式生成自然问题构成合理输入，并利用动态阈值过滤负样例，在不需要实体标签的情况下实现端到端的论元抽取，我们的方法引入了标签的先验信息，并且在低资源类别上有更好的表现。

第二篇论文是基于图卷积网络的篇章事件论元分类。

这篇论文的工作实际上是一个实体多分类。我们基于这样的考虑：1.当前句子事件的发生往往与前后发生的事件有联系，于是就构建了事件触发词之间的图，2. 相同类型的实体可能共享同一角色，构建了实体类型图，3. 依存关系可以捕获上下文依赖，构建了依存图。 融合3个图卷积网络最终做一个节点分类。

然后还参与做过一个**事件主体抽取**的评测任务。我主要使用一个两阶段的抽取框架。实体识别和事件分类作为pipeline模型，包含一个多标签分类，实体识别和问答框架。



此外，我也有去企业实习过，在苏州微软做过邮件文本分类的相关工作。

项目的背景是部门每天会收到大量邮件，需要找出其中与部门相关的邮件即可。

- 由于标注数据困难，我们先在不平衡的数据上做了实验，选用CNN模型作为baseline，尝试了EDA+回译的数据增强，有明显提升，在此基础上并做了bagging的下采样+投票融合，最终F1值提升了10个多点。此外我们也尝试了一个无监督数据增强，但是效果一般。

- 另外，我们通过自然标注手段获取了一批1w条平衡数据，考虑到token的特点，我们采用了fasttext的预训练+TextCNN，可以达到F1约70%。我们同时也尝试了finetune BERT模型，可以做到79~80%。考虑到推理性能较慢，我们尝试了离线知识蒸馏方案，把bert作为teacher模型，利用cnn模型学习真实标签损失和bert的软标签的损失，F1和召回率有明显提升。

以上就是我个人的一些大致情况。