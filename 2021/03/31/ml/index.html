<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Gemini',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="本文整理了常用的机器学习算法以备面试。">
<meta name="keywords" content="ML">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习常用算法的整理">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2021&#x2F;03&#x2F;31&#x2F;ml&#x2F;index.html">
<meta property="og:site_name" content="讲个笑话">
<meta property="og:description" content="本文整理了常用的机器学习算法以备面试。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2021&#x2F;03&#x2F;31&#x2F;ml&#x2F;svm.jpg">
<meta property="og:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2021&#x2F;03&#x2F;31&#x2F;ml&#x2F;k-means_1.png">
<meta property="og:updated_time" content="2021-06-22T13:12:32.815Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2021&#x2F;03&#x2F;31&#x2F;ml&#x2F;svm.jpg">

<link rel="canonical" href="http://yoursite.com/2021/03/31/ml/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>机器学习常用算法的整理 | 讲个笑话</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">讲个笑话</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">能力随心，自然成长</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
        <li class="menu-item menu-item-paper">

    <a href="/paper/" rel="section"><i class="fa fa-fw fa-file-text"></i>论文</a>

  </li>
        <li class="menu-item menu-item-feeling">

    <a href="/feeling/" rel="section"><i class="fa fa-fw fa-pencil"></i>随笔</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/03/31/ml/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://gss0.baidu.com/94o3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=8beb6236895494ee8777071f1dc5ccc6/6159252dd42a28344caed5825eb5c9ea15cebf2b.jpg">
      <meta itemprop="name" content="mchen">
      <meta itemprop="description" content="天青色等烟雨，而我在等你">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="讲个笑话">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习常用算法的整理
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2021-03-31 16:40:15" itemprop="dateCreated datePublished" datetime="2021-03-31T16:40:15+08:00">2021-03-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-06-22 21:12:32" itemprop="dateModified" datetime="2021-06-22T21:12:32+08:00">2021-06-22</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本文整理了常用的机器学习算法以备面试。</p>
<a id="more"></a>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><ul>
<li><p>逻辑回归的基本假设：假设数据服从<strong>伯努利分布</strong>，以p概率取1，1-p概率取0，这样的模型就是逻辑斯蒂回归模型</p>
</li>
<li><p>逻辑回归的损失函数：最大化对数似然， 使用<strong>梯度下降法</strong>来不断逼近最优解。</p>
</li>
<li><p><strong>为什么要用最大似然估计？</strong></p>
<ul>
<li>从求最优解的角度：用最小二乘的目标函数是非凸的，容易<strong>局部最优</strong>，而对数似然函数是一个凸函数，可以用梯度下降法来求解。</li>
<li>收敛速度：最小二乘的收敛速度慢，最大似然收敛快</li>
</ul>
<p>类似的问题：<a href="https://blog.csdn.net/saltriver/article/details/57544704" target="_blank" rel="noopener">线性回归为什么用最小二乘？</a></p>
<p> 最小二乘法以估计值与观测值的平方和作为损失函数，在误差服从正态分布的前提下，与极大似然估计的思想在本质上是相同。 </p>
</li>
<li><p>LR的优缺点</p>
<ul>
<li>优点：结构简单，可解释性强，训练速度快</li>
<li>缺点：很难拟合数据的真实分布，很难处理数据不平衡的问题，处理非线性数据比较麻烦。</li>
</ul>
</li>
<li><p>LR和SVM的区别：</p>
<ul>
<li><p>损失不同</p>
</li>
<li><p>LR是<strong>参数模型</strong>，SVM是非参数模型。 参数模型和非参数模型中的“参数”并不是模型中的参数，而是数据分布的参数。</p>
<ul>
<li><p>参数模型和非参数模型</p>
<p>​    参数机器学习模型由于指定了目标函数的形式，所以可以极大地简化这个学习的过程，但是同样会限制学习的过程。所以参数机器学习模型包括两个部分：1、选择合适的目标函数的形式。2、通过训练数据学习目标函数的参数。 </p>
<p> 非参数机器学习算法对目标函数形式不做过多的假设，因此算法可以通过对训练数据进行拟合而学习出某种形式的函数。 常见的非参数机器学习模型包括：决策树，朴素贝叶斯，SVM，神经网络。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>SVM不直接依赖数据分布，而LR则依赖，因为SVM只与支持向量那几个点有关系，而LR和所有点都有关系。 </li>
<li>LR是经验风险最小化模型（极大似然估计），SVM是结构风险最小化模型（等价于加了正则化）</li>
</ul>
<h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><p>SVM简单来说，对于线性可分的数据，最大化一个硬间隔支持向量机，近似可分时，最大化软间隔支持向量机，线性不可分时，使用<strong>核技巧</strong>学习非线性支持向量机。</p>
<ul>
<li><p>函数间隔和几何间隔</p>
<p>函数间隔受参数w影响，几何间隔除以L2范数，是确定的</p>
</li>
<li><p>对偶问题</p>
<p>对偶问题更容易求解，把目标函数和约束融为拉格朗日函数，通过这个函数来寻找最优解。</p>
<p>可以自然的引出核函数，进而推广到非线性分类问题</p>
</li>
<li><p>引入核函数</p>
<p>原本的样本空间线性不可分，通过核函数把样本映射到一个线性可分的空间去，这样以后，求解对偶问题只需知道核函数，求解难度下降。</p>
</li>
<li><p>核函数之间的区别</p>
<p>线性核：适用于线性可分，参数少，训练快</p>
<p>高斯核：适用于线性不可分，参数多，分类结果依赖于参数的好坏</p>
</li>
</ul>
<ul>
<li><p>手推SVM</p>
<p><img src="/2021/03/31/ml/svm.jpg" alt="avatar"></p>
</li>
</ul>
<h3 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h3><p>定义：对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的<strong>联合概率</strong>分布，然后基于该模型，对于给定的输入x，利用贝叶斯定理求出<strong>后验概率</strong>最大的输出y。</p>
<ul>
<li><p>为什么<strong>朴素</strong>？ 在计算P(X|Y)时引入了很强的特征独立，这样做可以避免求解时面临的组合爆炸和样本稀疏问题。 </p>
</li>
<li><p>优点： 对小规模的数据表现很好，适合多分类任务，适合增量式训练。收敛快。 </p>
</li>
<li>缺点： 对输入数据的表达形式很敏感（离散、连续，值极大极小之类的）。 条件独立性假设。</li>
</ul>
<h3 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h3><ul>
<li><p>算法原理：采用测量不同特征值间的距离或相似度的方法进行分类。如果一个样本在特征空间的K个最相似（最近邻）的样本中的大多数属于某个类别，则该样本也属于该类别。</p>
</li>
<li><p>算法决策过程：</p>
<ul>
<li>计算新数据与训练集中的特征相似度或距离</li>
<li>取TopK个最近邻的数据分类的标签</li>
<li>TopK中出现最多的作为最终的分类标签</li>
</ul>
</li>
<li>K的取值<ul>
<li>k值小：过拟合 噪声敏感</li>
<li>k值大：欠拟合 </li>
</ul>
</li>
<li>进阶：kd树</li>
</ul>
<h3 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h3><p> K-Means的一个重要的假设是：<strong>数据之间的相似度可以使用欧氏距离度量</strong>，<br>（注：<strong>可以使用欧氏距离度量</strong>的意思就是欧氏距离越小，两个数据相似度越高） </p>
<ul>
<li><p>算法步骤：</p>
</li>
<li><p><img src="/2021/03/31/ml/k-means_1.png" alt="avatar"></p>
</li>
<li><p>优点</p>
<ul>
<li>容易理解，聚类效果不错，虽然是局部最优（EM算法容易陷入局部最小值）， 但往往局部最优就够了；</li>
<li>处理大数据集的时候，该算法可以保证较好的伸缩性；</li>
<li>当簇近似高斯分布的时候，效果非常不错；</li>
<li>算法复杂度低。</li>
</ul>
</li>
<li><p>缺点</p>
<ul>
<li>K 值需要人为设定，不同 K 值得到的结果不一样；</li>
<li>对初始的簇中心敏感，不同选取方式会得到不同结果；</li>
<li>对异常值敏感；</li>
<li>样本只能归为一类，不适合多分类任务；</li>
<li>不适合太离散的分类、样本类别不平衡的分类、非凸形状的分类。</li>
</ul>
</li>
<li><p>改进</p>
<ul>
<li><p>数据预处理，去除异常点（数据归一化）</p>
</li>
<li><p>合理选择K值（手肘法）</p>
</li>
<li><p>基于欧式距离的 K-means 假设了了各个数据簇的数据具有一样的的先验概率并呈现球形分布，但这种分布在实际生活中并不常见。 </p>
<p>采用<strong>核函数</strong>， 主要思想是通过一个非线性映射，将输入空间中的数据点映射到高位的特征空间中，并在新的特征空间中进行聚类。 </p>
</li>
<li><p>二分k-means</p>
</li>
</ul>
</li>
<li><p>基础版K-means代码</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calDistance</span><span class="params">(vecA, vecB)</span>:</span>  <span class="comment"># 欧式距离</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">return</span> sum((vecA - vecB) ** <span class="number">2</span>) ** <span class="number">0.5</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initCentroids</span><span class="params">(dataSet, k)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">    numSamples, dim = dataSet.shape</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    centroids = np.zeros((k, dim))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">        index = int(np.random.uniform(<span class="number">0</span>, numSamples))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">        centroids[i, :] = dataSet[index, :]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">return</span> centroids</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">16</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">17</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">18</span></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmeans</span><span class="params">(dataSet, k)</span>:</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">19</span></pre></td><td class="code"><pre><span class="line">    numSamples = dataSet.shape[<span class="number">0</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">20</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># first column stores which cluster this sample belongs to,</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">21</span></pre></td><td class="code"><pre><span class="line">    <span class="comment"># second column stores the error between this sample and its centroid</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">22</span></pre></td><td class="code"><pre><span class="line">    clusterAssment = np.mat(np.zeros((numSamples, <span class="number">2</span>)))  <span class="comment"># np.mat 仅仅是生成矩阵 # 相当于np.matrix</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">23</span></pre></td><td class="code"><pre><span class="line">    clusterChanged = <span class="literal">True</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">24</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">25</span></pre></td><td class="code"><pre><span class="line">    <span class="comment">## step 1: 创建k个点作为起始质心</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">26</span></pre></td><td class="code"><pre><span class="line">    centroids = initCentroids(dataSet, k)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">27</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">28</span></pre></td><td class="code"><pre><span class="line">    <span class="keyword">while</span> clusterChanged:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">29</span></pre></td><td class="code"><pre><span class="line">        clusterChanged = <span class="literal">False</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">30</span></pre></td><td class="code"><pre><span class="line">        <span class="comment">## 对每个样本点</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">31</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(numSamples):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">32</span></pre></td><td class="code"><pre><span class="line">            minDist = np.inf</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">33</span></pre></td><td class="code"><pre><span class="line">            minIndex = <span class="number">0</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">34</span></pre></td><td class="code"><pre><span class="line">            <span class="comment">## step 2: 对每个质心</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">35</span></pre></td><td class="code"><pre><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">36</span></pre></td><td class="code"><pre><span class="line">                distance = calDistance(centroids[j, :], dataSet[i, :])</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">37</span></pre></td><td class="code"><pre><span class="line">                <span class="keyword">if</span> distance &lt; minDist:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">38</span></pre></td><td class="code"><pre><span class="line">                    minDist = distance</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">39</span></pre></td><td class="code"><pre><span class="line">                    minIndex = j</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">40</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">41</span></pre></td><td class="code"><pre><span class="line">            <span class="comment">## step 3: 将数据点分配到距其最近的簇</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">42</span></pre></td><td class="code"><pre><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">43</span></pre></td><td class="code"><pre><span class="line">                clusterChanged = <span class="literal">True</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">44</span></pre></td><td class="code"><pre><span class="line">                clusterAssment[i, :] = minIndex, minDist ** <span class="number">2</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">45</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">46</span></pre></td><td class="code"><pre><span class="line">        <span class="comment">## step 4: 更新质心</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">47</span></pre></td><td class="code"><pre><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(k):</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">48</span></pre></td><td class="code"><pre><span class="line">            pointsInCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>] == j)[<span class="number">0</span>]]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">49</span></pre></td><td class="code"><pre><span class="line">            centroids[j, :] = np.mean(pointsInCluster, axis=<span class="number">0</span>)  <span class="comment"># 把每个簇中的所有点的均值作为新的质心</span></span></pre></td></tr></table></figure>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><ul>
<li><p>几个基本概念：</p>
<ul>
<li>熵：表示随机变量不确定性的度量H(X)</li>
<li>条件熵：已知随机变量X的条件下随机变量Y的不确定性H(Y|X)</li>
<li>信息增益：表示得知特征X的信息而使得类Y的信息的不确定性减少的程度g(D) = H(D)-H(D|A)</li>
</ul>
</li>
<li><p>决策树生成的经典算法：ID3和C4.5 分别按照信息增益和信息增益比来选择特征</p>
</li>
<li><p>决策树的剪枝</p>
</li>
<li><p>CART算法</p>
<p>CART是给定输入随机变量X条件下输出随机变量Y的条件概率分布的学习方法。</p>
<p>它假设决策树是二叉树。 CART树的生成就是递归地构建二叉决策树的过程。对回归树用平方误差最小化准则，对分类树用基尼指数最小化准则，进行特征选择，生成二叉树。 </p>
</li>
</ul>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p><a href="https://zhuanlan.zhihu.com/p/86263786" target="_blank" rel="noopener">Random Forest、Adaboost、GBDT</a></p>
<p>   用随机的方式建立一个森林。RF 算法由很多决策树组成，每一棵决策树之间没有关联。建立完森林后，当有新样本进入时，每棵决策树都会分别进行判断，然后基于投票法给出分类结果。 </p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/03/25/crf/" rel="prev" title="条件随机场">
      <i class="fa fa-chevron-left"></i> 条件随机场
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/04/01/topK/" rel="next" title="最小的K个数的多种解法">
      最小的K个数的多种解法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归"><span class="nav-number">1.</span> <span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM"><span class="nav-number">2.</span> <span class="nav-text">SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#朴素贝叶斯"><span class="nav-number">3.</span> <span class="nav-text">朴素贝叶斯</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN"><span class="nav-number">4.</span> <span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-means"><span class="nav-number">5.</span> <span class="nav-text">K-means</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树"><span class="nav-number">6.</span> <span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#随机森林"><span class="nav-number">7.</span> <span class="nav-text">随机森林</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="mchen"
      src="https://gss0.baidu.com/94o3dSag_xI4khGko9WTAnF6hhy/zhidao/wh%3D600%2C800/sign=8beb6236895494ee8777071f1dc5ccc6/6159252dd42a28344caed5825eb5c9ea15cebf2b.jpg">
  <p class="site-author-name" itemprop="name">mchen</p>
  <div class="site-description" itemprop="description">天青色等烟雨，而我在等你</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xiaomindog" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xiaomindog" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1131651415@qq.com" title="E-Mail → mailto:1131651415@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        



<div class="copyright">

  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">mchen</span>
</div>
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.6.0
  </div>
-->
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  

  

</body>
</html>
